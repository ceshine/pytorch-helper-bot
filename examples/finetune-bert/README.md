# Fine-tuning BERT Examples

1. [01-BERT-sst2.ipynb](./01-BERT-sst2.ipynb): Fine-tuning BERT-base-uncased on SST-2 using `huggingface/transformers` and `huggingface/nlp`. 
    - Taken from [ceshine/transformer_to_rnn](https://github.com/ceshine/transformer_to_rnn/tree/20200616-blog-post). 
    - Reference: [[Failure Report] Distill Fine-tuned Transformers into Recurrent Neural Networks](https://blog.ceshine.net/post/failed-to-distill-transformer-into-rnn/).
    - PyTorch-Helper-Bot version: 0.6.0
